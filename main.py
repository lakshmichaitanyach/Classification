{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "def load_data(dataset):\n",
    "\tdata_dir, data_file = os.path.split(dataset)\n",
    "\tif (not os.path.exists(dataset)) or (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "\t\timport urllib\n",
    "\t\torigin = 'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "\t\tprint ('... downloading data from %s' %origin)\n",
    "\t\turllib.urlretrieve(origin, dataset)\n",
    "\n",
    "\t# load the dataset\n",
    "\tprint ('... loading data')\n",
    "\tf = gzip.open(dataset, 'rb')\n",
    "\ttrain_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\tf.close()\n",
    "\n",
    "\ttrain_set_x, train_set_y = shared_dataset(train_set)\n",
    "\tvalid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "\ttest_set_x, test_set_y = shared_dataset(test_set)\n",
    "\n",
    "\tsets = [(train_set_x, train_set_y), (valid_set_x, valid_set_y), (train_set_x, train_set_y)]\n",
    "\treturn sets\n",
    "\n",
    "def shared_dataset(data_xy, borrow=True):\n",
    "\tdata_x, data_y = data_xy\n",
    "\tshared_x = theano.shared(numpy.asarray(data_x, dtype=theano.config.floatX), borrow=borrow)\n",
    "\tshared_y = theano.shared(numpy.asarray(data_y, dtype=theano.config.floatX), borrow=borrow)\n",
    "\treturn shared_x, T.cast(shared_y, 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "class LogisticRegression(object):\n",
    "\tdef __init__(self, input, n_in, n_out):\n",
    "\t\tself.W = theano.shared(value=numpy.zeros((n_in, n_out), dtype=theano.config.floatX), name='W', borrow=True)\n",
    "\t\tself.b = theano.shared(value=numpy.zeros((n_out,), dtype=theano.config.floatX), name='b', borrow=True)\n",
    "\t\tself.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
    "\t\tself.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "\t\tself.params = [self.W, self.b]\n",
    "\n",
    "\tdef negative_log_likelihood(self, y):\n",
    "\t\treturn -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "\n",
    "\tdef errors(self, y):\n",
    "\t\tif y.ndim != self.y_pred.ndim:\n",
    "\t\t\traise TypeError('y should have the same shape as self.y_pred', ('y', target.type, 'y_pred', self.y_pred.type))\n",
    "\t\tif y.dtype.startswith('int'):\n",
    "\t\t\treturn T.mean(T.neq(self.y_pred, y))\n",
    "\t\telse:\n",
    "\t\t\traise NotImplementedError()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import numpy\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import *\n",
    "\n",
    "learning_rate = 0.05\n",
    "n_epochs = 50\n",
    "dataset = 'mnist.pkl.gz'\n",
    "batch_size = 5000\n",
    "\n",
    "# load datasets\n",
    "datasets = load_data(dataset)\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "# compute number of minibatches for all sets\n",
    "n_train_batches = int(train_set_x.get_value(borrow=True).shape[0] / batch_size)\n",
    "n_valid_batches = int(valid_set_x.get_value(borrow=True).shape[0] / batch_size)\n",
    "n_test_batches = int(test_set_x.get_value(borrow=True).shape[0] / batch_size)\n",
    "\n",
    "#print(n_train_batches)\n",
    "\n",
    "###################\n",
    "# build the model #\n",
    "###################\n",
    "print ('... building the model')\n",
    "index = T.lscalar()\t# index to minibatch\n",
    "x = T.matrix('x')\t# data of rasterized images\n",
    "y = T.ivector('y')\t# labels are 1D vector of int\n",
    "classifier = LogisticRegression(input=x, n_in=28*28, n_out=10)\t# logistic regression classifier\n",
    "cost = classifier.negative_log_likelihood(y)\t# cost to minimize during training\n",
    "\n",
    "test_model = theano.function(inputs=[index],\n",
    "\t\toutputs=classifier.errors(y),\n",
    "\t\tgivens={x: test_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "\t\t\ty: test_set_y[index * batch_size: (index + 1) * batch_size]})\n",
    "\n",
    "validate_model = theano.function(inputs=[index],\n",
    "\t\toutputs=classifier.errors(y),\n",
    "\t\tgivens={x: valid_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "\t\t\ty: valid_set_y[index * batch_size: (index + 1) * batch_size]})\n",
    "\n",
    "# model to show misclassified examples\n",
    "misclassified_model = theano.function(inputs=[index],\n",
    "        outputs=classifier.y_pred,\n",
    "\t\tgivens={x: test_set_x[index: (index + 1)]})\n",
    "\n",
    "# compute the gradient of cost with respect to theta = (W, b)\n",
    "g_W = T.grad(cost=cost, wrt=classifier.W)\n",
    "g_b = T.grad(cost=cost, wrt=classifier.b)\n",
    "\n",
    "# specify how to update the parameters of the model\n",
    "updates = [(classifier.W, classifier.W - learning_rate * g_W),\n",
    "\t(classifier.b, classifier.b - learning_rate * g_b)]\n",
    "\n",
    "train_model = theano.function(inputs=[index],\n",
    "\t\toutputs=cost,\n",
    "\t\tupdates=updates,\n",
    "\t\tgivens={x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "\t\t\ty: train_set_y[index * batch_size: (index + 1) * batch_size]})\n",
    "\n",
    "###############\n",
    "# train model #\n",
    "###############\n",
    "def train():\n",
    "\tprint ('... training the model')\n",
    "\tepoch = 0\n",
    "\twhile(epoch < n_epochs):\n",
    "\t\tepoch = epoch + 1\n",
    "\t\tfor minibatch_index in range(n_train_batches):\n",
    "\t\t\tminibatch_avg_cost = train_model(minibatch_index)\n",
    "\t\tprint ('training epoch %i' %epoch)\n",
    "\n",
    "def test():\n",
    "\tfor minibatch_index in range(n_test_batches):\n",
    "\t\tminibatch_mean_error = test_model(minibatch_index)\n",
    "\t\tprint ('testing minibatch %i and mean error = %f' %(minibatch_index, minibatch_mean_error))\n",
    "    \n",
    "\n",
    "def show_misclassified():\n",
    "\tfor i in range(n_test_batches * batch_size):\n",
    "\t\timage = test_set_x[i].eval()\n",
    "\t\tlabel = test_set_y[i].eval()\n",
    "\t\tprediction = misclassified_model(i)[0]\n",
    "\t\tif prediction != label:\n",
    "\t\t\tprint ('misclassified example found in test set at index %i' %i)\n",
    "\t\t\t# show actual image\n",
    "\t\t\timage = image.reshape(28, 28)\n",
    "\t\t\tplt.imshow(image, cmap=cm.gray)\n",
    "\t\t\tplt.xlabel('Actual ' + str(label))\n",
    "\t\t\tplt.ylabel('Prediction ' + str(prediction))\n",
    "\t\t\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training the model\n",
      "training epoch 1\n",
      "training epoch 2\n",
      "training epoch 3\n",
      "training epoch 4\n",
      "training epoch 5\n",
      "training epoch 6\n",
      "training epoch 7\n",
      "training epoch 8\n",
      "training epoch 9\n",
      "training epoch 10\n",
      "training epoch 11\n",
      "training epoch 12\n",
      "training epoch 13\n",
      "training epoch 14\n",
      "training epoch 15\n",
      "training epoch 16\n",
      "training epoch 17\n",
      "training epoch 18\n",
      "training epoch 19\n",
      "training epoch 20\n",
      "training epoch 21\n",
      "training epoch 22\n",
      "training epoch 23\n",
      "training epoch 24\n",
      "training epoch 25\n",
      "training epoch 26\n",
      "training epoch 27\n",
      "training epoch 28\n",
      "training epoch 29\n",
      "training epoch 30\n",
      "training epoch 31\n",
      "training epoch 32\n",
      "training epoch 33\n",
      "training epoch 34\n",
      "training epoch 35\n",
      "training epoch 36\n",
      "training epoch 37\n",
      "training epoch 38\n",
      "training epoch 39\n",
      "training epoch 40\n",
      "training epoch 41\n",
      "training epoch 42\n",
      "training epoch 43\n",
      "training epoch 44\n",
      "training epoch 45\n",
      "training epoch 46\n",
      "training epoch 47\n",
      "training epoch 48\n",
      "training epoch 49\n",
      "training epoch 50\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing minibatch 0 and mean error = 0.110200\n",
      "testing minibatch 1 and mean error = 0.116000\n",
      "testing minibatch 2 and mean error = 0.126200\n",
      "testing minibatch 3 and mean error = 0.111400\n",
      "testing minibatch 4 and mean error = 0.120200\n",
      "testing minibatch 5 and mean error = 0.116000\n",
      "testing minibatch 6 and mean error = 0.128800\n",
      "testing minibatch 7 and mean error = 0.120000\n",
      "testing minibatch 8 and mean error = 0.120600\n",
      "testing minibatch 9 and mean error = 0.127400\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
